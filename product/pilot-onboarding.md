# dbt Guardian â€” Pilot Onboarding Guide

> **Welcome to the dbt Guardian Test Generator pilot!**
> This guide will help you get set up and running in ~5 minutes.

**What you're testing**: A CLI tool that analyzes your dbt Core project, finds test coverage gaps, and generates PR-ready schema.yml files with test suggestions.

**Why we need your feedback**: We've built what we think is useful, but we need real-world validation from teams like yours. Your honest feedback (good and bad!) will shape the next version.

**Time commitment**: ~30 minutes total over 4 weeks:
- 10 min: Install + first run
- 10 min: Try on your actual dbt project
- 10 min: Feedback call (or async survey)

---

## What This Tool Does (v0.1)

âœ… **Analyzes your dbt project** â€” Reads `manifest.json` and `catalog.json` to understand models, columns, and existing tests

âœ… **Finds coverage gaps** â€” Detects untested columns using pattern-based logic:
- ID columns â†’ need `unique` + `not_null`
- Timestamp columns â†’ need `not_null`
- Status/type columns â†’ need `accepted_values`
- Foreign key columns â†’ need `relationships`

âœ… **Prioritizes gaps** â€” Ranks suggestions 1 (critical) to 5 (low priority) based on column importance

âœ… **Generates test YAML** â€” Outputs PR-ready `schema.yml` with simple tests + placeholders for complex tests

âœ… **Beautiful CLI output** â€” Color-coded, table-formatted coverage reports

### What's NOT in v0.1 (coming later)

âŒ **No PR automation** â€” You manually copy tests from generated YAML into your models/ directory
âŒ **No GitHub integration** â€” No automatic commits/pushes
âŒ **No dbt Cloud support** â€” Only works with dbt Core (requires local manifest.json)
âŒ **No warehouse queries** â€” Can't connect to Snowflake/Postgres directly (uses catalog.json instead)
âŒ **No autonomous agents** â€” You run CLI commands manually

---

## Prerequisites

Before installing, make sure you have:

1. **Python 3.11 or 3.12** (check: `python --version`)
2. **Poetry** (Python package manager) â€” [Install instructions](https://python-poetry.org/docs/#installation)
3. **A dbt Core project** (not dbt Cloud)
4. **manifest.json** in your dbt project (run `dbt compile` or `dbt run` if missing)
5. **Optional: catalog.json** for better column type detection (run `dbt docs generate`)

---

## Installation

### Step 1: Get the code

**Option A: Email/DM from CTO-Agent** (recommended for pilot)
- We'll send you a `.zip` file or private GitHub repo link
- Extract to a local directory

**Option B: Clone from GitHub** (if you have access)
```bash
git clone https://github.com/[org-name]/dbt-guardian.git
cd dbt-guardian
```

### Step 2: Install dependencies

```bash
cd dbt-guardian
poetry install
```

This installs all Python dependencies in an isolated virtual environment.

### Step 3: Activate the virtual environment

```bash
poetry shell
```

Your terminal prompt should change to show `(dbt-guardian-py3.11)` or similar.

### Step 4: Verify installation

```bash
dbt-guardian --version
```

You should see: `dbt-guardian, version 0.1.0`

---

## Quick Start (5 Minutes)

### 1. Analyze your dbt project

Point the tool at your dbt project directory:

```bash
dbt-guardian analyze /path/to/your/dbt/project
```

**Example output**:
```
ğŸ“Š dbt Guardian â€” Test Coverage Analysis

Project: my_analytics
Models: 47
Columns: 312
Tested columns: 89 (28.5%)
Untested columns: 223 (71.5%)

ğŸ”´ Critical gaps (Priority 1-2): 34 columns
ğŸŸ¡ Medium gaps (Priority 3): 67 columns
ğŸŸ¢ Low priority gaps (Priority 4-5): 122 columns

Top 10 Gaps (by priority):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model               â”‚ Column          â”‚ Priority â”‚ Reason   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ customers           â”‚ customer_id     â”‚ 1        â”‚ ID col   â”‚
â”‚ orders              â”‚ order_id        â”‚ 1        â”‚ ID col   â”‚
â”‚ customers           â”‚ email           â”‚ 2        â”‚ ID col   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Run `dbt-guardian generate-tests` to create test suggestions.
```

### 2. Generate test suggestions

```bash
dbt-guardian generate-tests /path/to/your/dbt/project --output test-suggestions.yml
```

**Output**: A `test-suggestions.yml` file with PR-ready test definitions.

**Example output**:
```yaml
# Generated by dbt Guardian Test Generator v0.1.0
# Date: 2026-02-16
# Project: my_analytics

models:
  - name: customers
    description: ""
    columns:
      - name: customer_id
        description: ""
        tests:
          - unique
          - not_null

      - name: email
        description: ""
        tests:
          - unique
          - not_null

      - name: status
        description: ""
        tests:
          - accepted_values:
              values: []  # TODO: Specify valid values
```

### 3. Copy tests to your project

**Manual process** (v0.1):
1. Open `test-suggestions.yml`
2. Copy the test definitions you want
3. Paste into your `models/schema.yml` (or create new YAML files)
4. Fill in placeholders (e.g., `TODO: Specify valid values`)
5. Run `dbt test` to validate

---

## Usage Examples

### See project metadata

```bash
dbt-guardian info /path/to/your/dbt/project
```

Shows: project name, number of models, columns, test coverage %.

### Analyze only critical gaps

```bash
dbt-guardian analyze /path/to/your/dbt/project --priority 1-2
```

Filters to show only high-priority gaps (ID columns, primary keys).

### Generate tests for specific models

```bash
dbt-guardian generate-tests /path/to/your/dbt/project --models customers,orders
```

(Note: This feature may not be implemented yet â€” ask CTO-Agent if needed!)

---

## Known Limitations

### What might not work perfectly:

1. **Complex dbt projects** (1000+ models): May be slow or hit memory limits (please report!)
2. **Non-standard naming conventions**: Our pattern detection expects `id`, `_id`, `_at`, `status`, etc. If your columns use different naming, we might miss gaps.
3. **Custom test types**: We only generate built-in dbt tests (not_null, unique, accepted_values, relationships). Custom tests require manual authoring.
4. **Incremental models**: May suggest tests that are already implicitly tested by your model logic.
5. **dbt Cloud projects**: Not supported yet â€” needs local manifest.json.

### What definitely won't work:

- Projects without `manifest.json` (run `dbt compile` first)
- dbt versions < 1.0 (we parse v4+ manifest schema)
- Non-dbt projects (obviously!)

---

## Troubleshooting

### "Command not found: dbt-guardian"

**Fix**: Make sure you ran `poetry shell` to activate the virtual environment.

### "manifest.json not found"

**Fix**: Run `dbt compile` or `dbt run` in your dbt project directory first.

### "Parser error: Invalid manifest schema"

**Fix**: Your manifest.json might be from an old dbt version (<1.0). Upgrade dbt and re-run `dbt compile`.

### Tool crashes or gives weird output

**Please report this!** We need to know about parser bugs. Send us:
- The error message
- Your dbt version (`dbt --version`)
- Project size (number of models)
- If possible, a sanitized copy of your `manifest.json`

---

## Feedback â€” We Need Your Help!

### How to give feedback

**Option 1: Feedback call** (preferred)
- We'll schedule a quick 20-minute call after you've tested the tool
- Structured questions, no sales pitch, just learning

**Option 2: Email/Slack** (async)
- Send your thoughts to: [cto-email@example.com] or Slack DM to @cto-agent
- We'll follow up with clarifying questions if needed

**Option 3: GitHub Issues** (for bugs)
- Report bugs or feature requests at: [GitHub Issues link]
- Include error messages, steps to reproduce, environment details

### What we're trying to learn

1. **Did the tool work on your project?** (Any crashes, errors, or weird output?)
2. **Were the test priorities correct?** (Did we flag the right columns as critical?)
3. **Did you actually use the suggestions?** (Copy tests into your project? Why or why not?)
4. **What's missing?** (What would make this 10x more useful?)
5. **Would you use this again?** (Honest answer!)

### What NOT to worry about

- **Suggesting features we'll never build** â€” Tell us your dream scenario, even if it's wild!
- **Being too critical** â€” We want honest feedback, not politeness
- **Installation struggles** â€” If setup was hard, that's valuable feedback too

---

## FAQ

### Q: Is this free?

**A**: Yes, the pilot is completely free. We haven't figured out pricing yet. In the future, this might be a paid product, but early pilot partners will always get special access.

### Q: Will you have access to our dbt project?

**A**: No. The tool runs 100% locally on your machine. It reads your manifest.json (which is already generated by dbt), but never sends data anywhere. No telemetry, no tracking, no cloud dependencies.

### Q: Can I share this with my team?

**A**: Yes! We'd love feedback from multiple people on your team. Just share this doc and the installation instructions.

### Q: What happens after the pilot?

**A**: We'll synthesize feedback, fix bugs, and build v0.2 (probably PR automation). Early pilot partners will get early access to future versions. We're not trying to sell you anything â€” just building something useful.

### Q: What if I hate it or it doesn't work?

**A**: Please tell us! Even "this tool is useless because X" is incredibly valuable feedback. We won't be offended.

### Q: Can I request features?

**A**: Absolutely! We have a rough roadmap (PR automation, dbt Cloud support, cross-stack remediation), but your input will shape priorities.

### Q: How long will this take?

**A**:
- First run: 5 minutes (install + analyze)
- Testing on real project: 5-10 minutes (generate tests, review suggestions)
- Feedback call: 20 minutes
- **Total: ~30 minutes over 4 weeks**

---

## What's Next

1. **Install the tool** (see Installation section above)
2. **Run on your dbt project** (start with `analyze`, then `generate-tests`)
3. **Let us know how it went** (email, Slack, or schedule feedback call)
4. **Stay tuned** for v0.2 (we'll keep you posted!)

---

## Contact & Support

- **Questions during setup?** Email [cto-email] or Slack DM @cto-agent
- **Found a bug?** [GitHub Issues link] or email with details
- **Want to chat?** We'll reach out to schedule a feedback call

**Thank you for being an early partner!** Your feedback is shaping the future of dbt Guardian.

---

*Last updated: 2026-02-16*
*Version: 1.0 (pilot onboarding doc for v0.1 tool)*
